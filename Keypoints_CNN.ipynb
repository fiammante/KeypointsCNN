{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bHaJuIQzwCM6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 11s 20ms/step - loss: 0.8269 - accuracy: 0.7012 - val_loss: 0.4929 - val_accuracy: 0.8152\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.5176 - accuracy: 0.8152 - val_loss: 0.4010 - val_accuracy: 0.8442\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.4365 - accuracy: 0.8472 - val_loss: 0.3502 - val_accuracy: 0.8688\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.3904 - accuracy: 0.8625 - val_loss: 0.3172 - val_accuracy: 0.8810\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3610 - accuracy: 0.8728 - val_loss: 0.3015 - val_accuracy: 0.8877\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.3385 - accuracy: 0.8802 - val_loss: 0.2887 - val_accuracy: 0.8925\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3189 - accuracy: 0.8878 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3051 - accuracy: 0.8932 - val_loss: 0.2718 - val_accuracy: 0.8955\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2880 - accuracy: 0.8974 - val_loss: 0.2682 - val_accuracy: 0.9018\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2788 - accuracy: 0.9013 - val_loss: 0.2705 - val_accuracy: 0.8993\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2643 - accuracy: 0.9059 - val_loss: 0.2537 - val_accuracy: 0.9075\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2539 - accuracy: 0.9096 - val_loss: 0.2647 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2402 - accuracy: 0.9142 - val_loss: 0.2621 - val_accuracy: 0.9032\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2303 - accuracy: 0.9173 - val_loss: 0.2714 - val_accuracy: 0.9033\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2240 - accuracy: 0.9191 - val_loss: 0.2579 - val_accuracy: 0.9093\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2167 - accuracy: 0.9199 - val_loss: 0.2577 - val_accuracy: 0.9072\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2058 - accuracy: 0.9254 - val_loss: 0.2602 - val_accuracy: 0.9058\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1988 - accuracy: 0.9278 - val_loss: 0.2594 - val_accuracy: 0.9102\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1931 - accuracy: 0.9302 - val_loss: 0.2720 - val_accuracy: 0.9070\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1859 - accuracy: 0.9321 - val_loss: 0.2482 - val_accuracy: 0.9155\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1767 - accuracy: 0.9352 - val_loss: 0.2584 - val_accuracy: 0.9138\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1680 - accuracy: 0.9376 - val_loss: 0.2778 - val_accuracy: 0.9097\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1668 - accuracy: 0.9367 - val_loss: 0.2593 - val_accuracy: 0.9145\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1589 - accuracy: 0.9409 - val_loss: 0.2696 - val_accuracy: 0.9110\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1521 - accuracy: 0.9436 - val_loss: 0.2846 - val_accuracy: 0.9145\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1480 - accuracy: 0.9442 - val_loss: 0.2766 - val_accuracy: 0.9128\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1432 - accuracy: 0.9462 - val_loss: 0.2846 - val_accuracy: 0.9127\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1372 - accuracy: 0.9484 - val_loss: 0.3016 - val_accuracy: 0.9100\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1316 - accuracy: 0.9511 - val_loss: 0.3002 - val_accuracy: 0.9122\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1276 - accuracy: 0.9494 - val_loss: 0.2989 - val_accuracy: 0.9122\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1264 - accuracy: 0.9513 - val_loss: 0.3068 - val_accuracy: 0.9128\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1217 - accuracy: 0.9529 - val_loss: 0.3323 - val_accuracy: 0.9113\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1151 - accuracy: 0.9557 - val_loss: 0.3152 - val_accuracy: 0.9123\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1151 - accuracy: 0.9564 - val_loss: 0.3406 - val_accuracy: 0.9090\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1096 - accuracy: 0.9581 - val_loss: 0.3474 - val_accuracy: 0.9122\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.3402 - val_accuracy: 0.9098\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1051 - accuracy: 0.9591 - val_loss: 0.3373 - val_accuracy: 0.9128\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1032 - accuracy: 0.9596 - val_loss: 0.3440 - val_accuracy: 0.9133\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0989 - accuracy: 0.9617 - val_loss: 0.3560 - val_accuracy: 0.9083\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0958 - accuracy: 0.9619 - val_loss: 0.3947 - val_accuracy: 0.9133\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0950 - accuracy: 0.9630 - val_loss: 0.3610 - val_accuracy: 0.9125\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 0.4016 - val_accuracy: 0.9108\n",
      "Epoch 43/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.3855 - val_accuracy: 0.9140\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0859 - accuracy: 0.9660 - val_loss: 0.4201 - val_accuracy: 0.9128\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0825 - accuracy: 0.9681 - val_loss: 0.4343 - val_accuracy: 0.9087\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0850 - accuracy: 0.9669 - val_loss: 0.4091 - val_accuracy: 0.9118\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0849 - accuracy: 0.9669 - val_loss: 0.4122 - val_accuracy: 0.9128\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0805 - accuracy: 0.9684 - val_loss: 0.4161 - val_accuracy: 0.9112\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0767 - accuracy: 0.9692 - val_loss: 0.4694 - val_accuracy: 0.9093\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0762 - accuracy: 0.9699 - val_loss: 0.4544 - val_accuracy: 0.9067\n",
      "Test loss: 0.4718182682991028\n",
      "Test accuracy: 0.9043999910354614\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Title: Simple Fashion MNIST convnet\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Setup\n",
    "\"\"\"\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_1.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16 2 2 0 0\n"
     ]
    }
   ],
   "source": [
    "import receptive_field as rf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from receptive_field.python.util import graph_compute_order\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\",name=\"output\"),\n",
    "    ])\n",
    "    #for i, layer in enumerate(model.layers):\n",
    "    #   print(i, layer.name)\n",
    "\n",
    "node_info, name_to_node = graph_compute_order.get_compute_order(\n",
    "      graph_def=g.as_graph_def(),\n",
    "      input_node_name='input_1',\n",
    "      input_node_size=None)\n",
    "#for node in node_info.items():\n",
    "#     print(node[0])\n",
    "        \n",
    "\n",
    "\n",
    "# Compute receptive field parameters.\n",
    "rf_x, rf_y, eff_stride_x, eff_stride_y, eff_pad_x, eff_pad_y = \\\n",
    "  rf.compute_receptive_field_from_graph_def( \\\n",
    "    g.as_graph_def(), 'input_1', 'max_pooling2d_2/MaxPool')\n",
    "print(rf_x, rf_y, eff_stride_x, eff_stride_y, eff_pad_x, eff_pad_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (28, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMIN-~1\\AppData\\Local\\Temp/ipykernel_2532/1224393016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0maddmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgadd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mimgmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgadd\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0maddmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimgmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2903\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2904\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5607\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5609\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5610\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5611\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    707\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    708\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 709\u001b[1;33m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[0;32m    710\u001b[0m                             .format(self._A.shape))\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (28, 28, 28) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "# test masking with ORB Keypoints on sample image\n",
    "# \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = (X_train[0,:,:]*255).astype(np.uint8)\n",
    "#img = cv.cvtColor(img,cv.COLOR_GRAY2RGB)\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create(edgeThreshold=3, patchSize=2, nlevels=2, fastThreshold=7, scaleFactor=7,\n",
    "                    WTA_K=4,scoreType=cv.ORB_HARRIS_SCORE, firstLevel=0, nfeatures=64)\n",
    "def get_ORB_all(orb,img):\n",
    "    img = cv.equalizeHist(img)\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp , des = orb.compute(img, kp)\n",
    "    for k in kp:\n",
    "        x = int(k.pt[0])\n",
    "        y = int(k.pt[1])\n",
    "        s = int(k.size)\n",
    "        #print(\"x\",x,\"y\",y,\"size\",s)\n",
    "    # draw only keypoints location,not size and orientation\n",
    "    img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=4)\n",
    "    img3 = cv.drawKeypoints(img*0, kp, None, color=(255,255,255), flags=4)\n",
    "    gray = cv.cvtColor(img3, cv.COLOR_BGR2GRAY)\n",
    "    # Otsu's thresholding\n",
    "    ret2,mask = cv.threshold(gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return img2,img3,mask\n",
    "    return mask\n",
    "img2,img3,mask=get_ORB_all(orb,img)\n",
    "plt.imshow(img, cmap='gray'), plt.show()\n",
    "plt.imshow(img2), plt.show()\n",
    "plt.imshow(mask, cmap='gray'), plt.show()\n",
    "masked = cv.bitwise_and(img, img, mask=mask)\n",
    "plt.imshow(masked, cmap='gray'), plt.show()\n",
    "imgadd=(1.0*img+1.0*mask)\n",
    "imgmax=np.amax(img)\n",
    "addmax=np.amax(imgadd)\n",
    "imgmask=((imgadd/addmax)*imgmax).astype(np.uint8)\n",
    "plt.imshow(imgmask, cmap='gray'), plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create keypoint  train set\n",
      "create keypoint  test set\n",
      "Train Discriminator\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 43266     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,586\n",
      "Trainable params: 43,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(120000, 28, 28, 1)\n",
      "Epoch 1/5\n",
      "657/657 [==============================] - 14s 19ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 12s 18ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "(20000, 28, 28, 1)\n",
      "Test loss: 0.0022695427760481834\n",
      "Test accuracy: 0.9994500279426575\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# CNN to discriminante between Keypoints and no Keypoints areas\n",
    "# \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import cv2 as cv\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "# define Keypoint masking method\n",
    "def get_mask(img):\n",
    "    orb = cv.ORB_create(edgeThreshold=3, patchSize=2, nlevels=2, fastThreshold=7, scaleFactor=7,\n",
    "                    WTA_K=4,scoreType=cv.ORB_HARRIS_SCORE, firstLevel=0, nfeatures=64)\n",
    "    reduce=1\n",
    "    imgm = reduce*(img//reduce)\n",
    "    imgm = cv.equalizeHist(imgm)\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(imgm,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp , des = orb.compute(imgm, kp)\n",
    "    for k in kp:\n",
    "        x = int(k.pt[0])\n",
    "        y = int(k.pt[1])\n",
    "        s = int(k.size)\n",
    "        #print(\"x\",x,\"y\",y,\"size\",s)\n",
    "    # draw only keypoints location,not size and orientation\n",
    "    img3 = cv.drawKeypoints(imgm*0, kp, None, color=(255,255,255), flags=4)\n",
    "    gray = cv.cvtColor(img3, cv.COLOR_BGR2GRAY)\n",
    "    # Otsu's thresholding\n",
    "    ret2,mask = cv.threshold(gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return mask\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 2\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "# create train set\n",
    "print(\"create keypoint  train set\")\n",
    "(x,l,c)=X_train.shape\n",
    "X_train_mask=  np.zeros((2*x,l,c)).astype(\"float32\")\n",
    "Y_train_mask=  np.zeros(2*x)\n",
    "for i,img in enumerate(X_train):\n",
    "    mask=get_mask(img).astype(\"float32\")/255\n",
    "    img=img.astype(\"float32\")/255\n",
    "    X_train_mask[2*i+1]=img*mask\n",
    "    Y_train_mask[2*i+1]=0\n",
    "    negativemask=1-mask\n",
    "    X_train_mask[2*i]=img*negativemask\n",
    "    Y_train_mask[2*i]=1\n",
    "X_train_mask  = np.expand_dims(X_train_mask , -1)\n",
    "print(\"create keypoint  test set\") \n",
    "# create test set with each FashionMnist image first masked with keypoint zones \n",
    "# then another image using the negative mask\n",
    "(x,l,c)=X_test.shape\n",
    "X_test_mask=  np.zeros((2*x,l,c)).astype(\"float32\")\n",
    "Y_test_mask=  np.zeros(2*x)\n",
    "for i,img in enumerate(X_test):\n",
    "    mask=get_mask(img).astype(\"float32\")/255\n",
    "    img=img.astype(\"float32\")/255\n",
    "    X_test_mask[2*i+1]=img*mask\n",
    "    Y_test_mask[2*i+1]=0\n",
    "    negativemask=1-mask\n",
    "    X_test_mask[2*i]=img*negativemask\n",
    "    Y_test_mask[2*i]=1\n",
    "\n",
    "X_test_mask  = np.expand_dims(X_test_mask , -1)\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train_mask = keras.utils.to_categorical(Y_train_mask, num_classes)\n",
    "Y_test_mask = keras.utils.to_categorical(Y_test_mask, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "## Build the model to discriminate between keypoints and non keypoints\n",
    "\"\"\"\n",
    "print(\"Train Discriminator\")\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3),strides=(1, 1), activation=\"relu\"),\n",
    "        layers.Dropout(0.5),        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model small number of Epochs as it converges quicklu\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(X_train_mask.shape)\n",
    "model.fit(X_train_mask , Y_train_mask, batch_size=batch_size, epochs=epochs, validation_split=0.3)\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "print(X_test_mask.shape)\n",
    "score = model.evaluate(X_test_mask , Y_test_mask, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d\n",
      "conv2d (3, 3, 1, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_mask.shape (20000, 28, 28, 1)\n",
      "img.shape (1, 28, 28, 1)\n",
      "(1, 26, 26, 32)\n",
      "0.9887488 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape (1, 28, 28, 1)\n",
      "(1, 26, 26, 32)\n",
      "0.8218361 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "# recover weights, display filters and one example of features\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "pyplot.rcParams[\"figure.figsize\"] = (15,10)\n",
    "def plot_feature_maps(feature_maps,rows,cols):\n",
    "    print(np.amax(feature_maps),np.amin(feature_maps))\n",
    "    feature_maps=np.where(feature_maps>0.5,1,0)\n",
    "    ix = 1\n",
    "    for _ in range(rows):\n",
    "        for _ in range(cols):\n",
    "            # specify subplot and turn of axis\n",
    "            ax = pyplot.subplot(rows, cols, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "            ix += 1\n",
    "    pyplot.show() \n",
    "    \n",
    "# recover weights and save them to pickle file\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=layer.get_weights()\n",
    "        filters, biases=weights\n",
    "        pickle.dump( (filters, biases), open( \"weights_save.p\", \"wb\" ) )\n",
    "        pyplot.show()\n",
    "        rows=4\n",
    "        cols=8\n",
    "        # normalize filter values to 0-1 so we can visualize them\n",
    "        f, axs = pyplot.subplots(rows, cols, sharey=True)\n",
    "        n_filters, ix = filters.shape[-1], 0\n",
    "        for i in range(n_filters):\n",
    "            # get the filter\n",
    "            f = filters[:, :, :, i]\n",
    "            # specify subplot and turn of axis\n",
    "            row=ix//cols\n",
    "            col=ix-cols*row\n",
    "            ax=axs[row,col]\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            ax.imshow(f[:, :, 0], cmap='gray')\n",
    "            ix += 1\n",
    "        # show the figure\n",
    "        pyplot.show()\n",
    "        # load the image with the required shape\n",
    "        print(\"X_test_mask.shape\",X_test_mask.shape)\n",
    "        img = X_test_mask[0,:,:,:]\n",
    "        # expand dimensions so that it represents a single 'sample'\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        print(\"img.shape\",img.shape)\n",
    "        # get feature map for first hidden layer\n",
    "        # redefine model to output right after the first hidden layer\n",
    "        model_ = tf.keras.Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "        feature_maps = model_(img)\n",
    "        print(feature_maps.shape)\n",
    "        # plot all 32 maps \n",
    "        \n",
    "        plot_feature_maps(feature_maps,rows,cols)\n",
    "        \n",
    "        # second one\n",
    "        img = X_test_mask[1,:,:,:]\n",
    "        # expand dimensions so that it represents a single 'sample'\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        print(\"img.shape\",img.shape)\n",
    "        # get feature map for first hidden layer\n",
    "        # redefine model to output right after the first hidden layer\n",
    "        feature_maps = model_(img)\n",
    "        print(feature_maps.shape)\n",
    "        plot_feature_maps(feature_maps,rows,cols)\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "conv2d_4\n",
      "max_pooling2d_2\n",
      "conv2d_5\n",
      "max_pooling2d_3\n",
      "conv2d_6\n",
      "conv2d_7\n",
      "flatten_1\n",
      "dropout_1\n",
      "dense_1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.8157 - accuracy: 0.7056 - val_loss: 0.4654 - val_accuracy: 0.8210\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.5190 - accuracy: 0.8143 - val_loss: 0.4038 - val_accuracy: 0.8515\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4437 - accuracy: 0.8420 - val_loss: 0.3469 - val_accuracy: 0.8737\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3912 - accuracy: 0.8624 - val_loss: 0.3227 - val_accuracy: 0.8792\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3636 - accuracy: 0.8719 - val_loss: 0.3244 - val_accuracy: 0.8820\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3451 - accuracy: 0.8774 - val_loss: 0.2965 - val_accuracy: 0.8917\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3238 - accuracy: 0.8863 - val_loss: 0.2791 - val_accuracy: 0.8958\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3085 - accuracy: 0.8913 - val_loss: 0.2721 - val_accuracy: 0.8995\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2902 - accuracy: 0.8976 - val_loss: 0.2645 - val_accuracy: 0.9010\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2766 - accuracy: 0.9016 - val_loss: 0.2533 - val_accuracy: 0.9053\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2640 - accuracy: 0.9058 - val_loss: 0.2550 - val_accuracy: 0.9078\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2561 - accuracy: 0.9095 - val_loss: 0.2439 - val_accuracy: 0.9120\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2446 - accuracy: 0.9132 - val_loss: 0.2491 - val_accuracy: 0.9088\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2327 - accuracy: 0.9161 - val_loss: 0.2483 - val_accuracy: 0.9147\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2245 - accuracy: 0.9188 - val_loss: 0.2402 - val_accuracy: 0.9180\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2176 - accuracy: 0.9220 - val_loss: 0.2386 - val_accuracy: 0.9140\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2092 - accuracy: 0.9246 - val_loss: 0.2391 - val_accuracy: 0.9173\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2013 - accuracy: 0.9274 - val_loss: 0.2566 - val_accuracy: 0.9102\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1945 - accuracy: 0.9299 - val_loss: 0.2417 - val_accuracy: 0.9175\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1849 - accuracy: 0.9319 - val_loss: 0.2462 - val_accuracy: 0.9132\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1777 - accuracy: 0.9346 - val_loss: 0.2525 - val_accuracy: 0.9238\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1716 - accuracy: 0.9375 - val_loss: 0.2423 - val_accuracy: 0.9227\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1692 - accuracy: 0.9379 - val_loss: 0.2598 - val_accuracy: 0.9210\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1604 - accuracy: 0.9419 - val_loss: 0.2576 - val_accuracy: 0.9147\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1557 - accuracy: 0.9409 - val_loss: 0.2595 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1527 - accuracy: 0.9432 - val_loss: 0.2802 - val_accuracy: 0.9187\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1480 - accuracy: 0.9453 - val_loss: 0.2699 - val_accuracy: 0.9200\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1398 - accuracy: 0.9479 - val_loss: 0.2861 - val_accuracy: 0.9165\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1352 - accuracy: 0.9479 - val_loss: 0.2999 - val_accuracy: 0.9095\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1294 - accuracy: 0.9508 - val_loss: 0.2900 - val_accuracy: 0.9188\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1289 - accuracy: 0.9514 - val_loss: 0.2775 - val_accuracy: 0.9183\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1212 - accuracy: 0.9543 - val_loss: 0.3008 - val_accuracy: 0.9148\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1197 - accuracy: 0.9532 - val_loss: 0.2868 - val_accuracy: 0.9168\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1177 - accuracy: 0.9544 - val_loss: 0.3253 - val_accuracy: 0.9145\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1142 - accuracy: 0.9566 - val_loss: 0.3178 - val_accuracy: 0.9190\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1078 - accuracy: 0.9585 - val_loss: 0.3210 - val_accuracy: 0.9153\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1063 - accuracy: 0.9592 - val_loss: 0.3126 - val_accuracy: 0.9180\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1033 - accuracy: 0.9600 - val_loss: 0.3448 - val_accuracy: 0.9210\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1050 - accuracy: 0.9586 - val_loss: 0.3470 - val_accuracy: 0.9210\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.3613 - val_accuracy: 0.9163\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0918 - accuracy: 0.9635 - val_loss: 0.3470 - val_accuracy: 0.9142\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0898 - accuracy: 0.9650 - val_loss: 0.3697 - val_accuracy: 0.9170\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0898 - accuracy: 0.9657 - val_loss: 0.3607 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0875 - accuracy: 0.9660 - val_loss: 0.3746 - val_accuracy: 0.9100\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0860 - accuracy: 0.9664 - val_loss: 0.4014 - val_accuracy: 0.9163\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0826 - accuracy: 0.9677 - val_loss: 0.3988 - val_accuracy: 0.9170\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0776 - accuracy: 0.9691 - val_loss: 0.3804 - val_accuracy: 0.9147\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0810 - accuracy: 0.9680 - val_loss: 0.4250 - val_accuracy: 0.9165\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0817 - accuracy: 0.9674 - val_loss: 0.4302 - val_accuracy: 0.9158\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0760 - accuracy: 0.9702 - val_loss: 0.4531 - val_accuracy: 0.9195\n",
      "Test loss: 0.47225576639175415\n",
      "Test accuracy: 0.9150999784469604\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now transfer learned keypoint discriminator layer to FashionMnist categorization CNN\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Transfer the weights\n",
    "\"\"\"\n",
    "for layer in model_2.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=pickle.load( open( \"weights_save.p\", \"rb\" ) )\n",
    "        layer.set_weights(weights)\n",
    "        #layer.trainable = False  \n",
    "\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_2.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "conv2d_8\n",
      "max_pooling2d_4\n",
      "conv2d_9\n",
      "max_pooling2d_5\n",
      "conv2d_10\n",
      "conv2d_11\n",
      "flatten_2\n",
      "dropout_2\n",
      "dense_2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 9s 19ms/step - loss: 0.8094 - accuracy: 0.7126 - val_loss: 0.4505 - val_accuracy: 0.8308\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4974 - accuracy: 0.8251 - val_loss: 0.3695 - val_accuracy: 0.8598\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4243 - accuracy: 0.8501 - val_loss: 0.3405 - val_accuracy: 0.8748\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3803 - accuracy: 0.8672 - val_loss: 0.3004 - val_accuracy: 0.8878\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.3522 - accuracy: 0.8778 - val_loss: 0.2860 - val_accuracy: 0.8935\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3276 - accuracy: 0.8855 - val_loss: 0.2743 - val_accuracy: 0.8958\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.3065 - accuracy: 0.8930 - val_loss: 0.2919 - val_accuracy: 0.8865\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2930 - accuracy: 0.8975 - val_loss: 0.2652 - val_accuracy: 0.9037\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2766 - accuracy: 0.9025 - val_loss: 0.2789 - val_accuracy: 0.8960\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2648 - accuracy: 0.9062 - val_loss: 0.2468 - val_accuracy: 0.9097\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2521 - accuracy: 0.9099 - val_loss: 0.2499 - val_accuracy: 0.9090\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2432 - accuracy: 0.9139 - val_loss: 0.2445 - val_accuracy: 0.9158\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2302 - accuracy: 0.9170 - val_loss: 0.2381 - val_accuracy: 0.9112\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2244 - accuracy: 0.9197 - val_loss: 0.2482 - val_accuracy: 0.9095\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2146 - accuracy: 0.9227 - val_loss: 0.2562 - val_accuracy: 0.9103\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2032 - accuracy: 0.9258 - val_loss: 0.2628 - val_accuracy: 0.9087\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1979 - accuracy: 0.9271 - val_loss: 0.2533 - val_accuracy: 0.9138\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.1902 - accuracy: 0.9306 - val_loss: 0.2510 - val_accuracy: 0.9142\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1810 - accuracy: 0.9337 - val_loss: 0.2595 - val_accuracy: 0.9113\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1756 - accuracy: 0.9354 - val_loss: 0.2577 - val_accuracy: 0.9150\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1672 - accuracy: 0.9387 - val_loss: 0.2555 - val_accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1626 - accuracy: 0.9396 - val_loss: 0.2558 - val_accuracy: 0.9190\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.1562 - accuracy: 0.9418 - val_loss: 0.2536 - val_accuracy: 0.9165\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1500 - accuracy: 0.9443 - val_loss: 0.2559 - val_accuracy: 0.9165\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1432 - accuracy: 0.9464 - val_loss: 0.2790 - val_accuracy: 0.9157\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1382 - accuracy: 0.9469 - val_loss: 0.3006 - val_accuracy: 0.9105\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1355 - accuracy: 0.9481 - val_loss: 0.2752 - val_accuracy: 0.9180\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.2806 - val_accuracy: 0.9143\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1247 - accuracy: 0.9524 - val_loss: 0.2887 - val_accuracy: 0.9168\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1202 - accuracy: 0.9541 - val_loss: 0.3077 - val_accuracy: 0.9142\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1172 - accuracy: 0.9554 - val_loss: 0.3107 - val_accuracy: 0.9162\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1130 - accuracy: 0.9565 - val_loss: 0.3090 - val_accuracy: 0.9155\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1102 - accuracy: 0.9580 - val_loss: 0.3322 - val_accuracy: 0.9080\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1067 - accuracy: 0.9585 - val_loss: 0.3321 - val_accuracy: 0.9130\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1046 - accuracy: 0.9601 - val_loss: 0.3616 - val_accuracy: 0.9103\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1005 - accuracy: 0.9614 - val_loss: 0.3466 - val_accuracy: 0.9122\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1020 - accuracy: 0.9601 - val_loss: 0.3437 - val_accuracy: 0.9142\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0979 - accuracy: 0.9613 - val_loss: 0.3668 - val_accuracy: 0.9117\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0962 - accuracy: 0.9624 - val_loss: 0.3637 - val_accuracy: 0.9073\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0901 - accuracy: 0.9645 - val_loss: 0.3805 - val_accuracy: 0.9112\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0858 - accuracy: 0.9655 - val_loss: 0.3870 - val_accuracy: 0.9100\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0904 - accuracy: 0.9643 - val_loss: 0.4023 - val_accuracy: 0.9122\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0837 - accuracy: 0.9670 - val_loss: 0.4234 - val_accuracy: 0.9083\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0824 - accuracy: 0.9675 - val_loss: 0.4059 - val_accuracy: 0.9128\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.0800 - accuracy: 0.9686 - val_loss: 0.4351 - val_accuracy: 0.9107\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0788 - accuracy: 0.9692 - val_loss: 0.4247 - val_accuracy: 0.9120\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.4440 - val_accuracy: 0.9130\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0756 - accuracy: 0.9701 - val_loss: 0.4533 - val_accuracy: 0.9097\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0739 - accuracy: 0.9707 - val_loss: 0.4507 - val_accuracy: 0.9100\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0717 - accuracy: 0.9721 - val_loss: 0.4473 - val_accuracy: 0.9093\n",
      "Test loss: 0.48668134212493896\n",
      "Test accuracy: 0.9110999703407288\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Freezing keypoint layer  \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import pickle\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_3 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "## Transfer the weights freeze learning\n",
    "\"\"\"\n",
    "for layer in model_3.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=pickle.load( open( \"weights_save.p\", \"rb\" ) )\n",
    "        layer.set_weights(weights)\n",
    "        layer.trainable = False  \n",
    "\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_3.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN - InceptionResNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
