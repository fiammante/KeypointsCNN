{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 4 4 0 0\n"
     ]
    }
   ],
   "source": [
    "# use receptive field computation from Google research https://github.com/google-research/receptive_field\n",
    "# to construct a CNN that has a minimum of 26x26 pixels receptive field\n",
    "# see above link to install ffrom github\n",
    "\n",
    "import receptive_field as rf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from receptive_field.python.util import graph_compute_order\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1, 1)), # dummy layer for receptive field to identify the last layer for computation.\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\",name=\"output\"),\n",
    "    ])\n",
    "    #for i, layer in enumerate(model.layers):\n",
    "    #   print(i, layer.name)\n",
    "\n",
    "node_info, name_to_node = graph_compute_order.get_compute_order(\n",
    "      graph_def=g.as_graph_def(),\n",
    "      input_node_name='input_1',\n",
    "      input_node_size=None)\n",
    "#for node in node_info.items():\n",
    "#     print(node[0])\n",
    "        \n",
    "\n",
    "\n",
    "# Compute receptive field parameters.\n",
    "rf_x, rf_y, eff_stride_x, eff_stride_y, eff_pad_x, eff_pad_y = \\\n",
    "  rf.compute_receptive_field_from_graph_def( \\\n",
    "    g.as_graph_def(), 'input_1', 'max_pooling2d_2/MaxPool')\n",
    "print(rf_x, rf_y, eff_stride_x, eff_stride_y, eff_pad_x, eff_pad_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bHaJuIQzwCM6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 11s 20ms/step - loss: 0.8269 - accuracy: 0.7012 - val_loss: 0.4929 - val_accuracy: 0.8152\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.5176 - accuracy: 0.8152 - val_loss: 0.4010 - val_accuracy: 0.8442\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.4365 - accuracy: 0.8472 - val_loss: 0.3502 - val_accuracy: 0.8688\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.3904 - accuracy: 0.8625 - val_loss: 0.3172 - val_accuracy: 0.8810\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3610 - accuracy: 0.8728 - val_loss: 0.3015 - val_accuracy: 0.8877\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.3385 - accuracy: 0.8802 - val_loss: 0.2887 - val_accuracy: 0.8925\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3189 - accuracy: 0.8878 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3051 - accuracy: 0.8932 - val_loss: 0.2718 - val_accuracy: 0.8955\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2880 - accuracy: 0.8974 - val_loss: 0.2682 - val_accuracy: 0.9018\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2788 - accuracy: 0.9013 - val_loss: 0.2705 - val_accuracy: 0.8993\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2643 - accuracy: 0.9059 - val_loss: 0.2537 - val_accuracy: 0.9075\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2539 - accuracy: 0.9096 - val_loss: 0.2647 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2402 - accuracy: 0.9142 - val_loss: 0.2621 - val_accuracy: 0.9032\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2303 - accuracy: 0.9173 - val_loss: 0.2714 - val_accuracy: 0.9033\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2240 - accuracy: 0.9191 - val_loss: 0.2579 - val_accuracy: 0.9093\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2167 - accuracy: 0.9199 - val_loss: 0.2577 - val_accuracy: 0.9072\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2058 - accuracy: 0.9254 - val_loss: 0.2602 - val_accuracy: 0.9058\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1988 - accuracy: 0.9278 - val_loss: 0.2594 - val_accuracy: 0.9102\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1931 - accuracy: 0.9302 - val_loss: 0.2720 - val_accuracy: 0.9070\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1859 - accuracy: 0.9321 - val_loss: 0.2482 - val_accuracy: 0.9155\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1767 - accuracy: 0.9352 - val_loss: 0.2584 - val_accuracy: 0.9138\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1680 - accuracy: 0.9376 - val_loss: 0.2778 - val_accuracy: 0.9097\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1668 - accuracy: 0.9367 - val_loss: 0.2593 - val_accuracy: 0.9145\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1589 - accuracy: 0.9409 - val_loss: 0.2696 - val_accuracy: 0.9110\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1521 - accuracy: 0.9436 - val_loss: 0.2846 - val_accuracy: 0.9145\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1480 - accuracy: 0.9442 - val_loss: 0.2766 - val_accuracy: 0.9128\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1432 - accuracy: 0.9462 - val_loss: 0.2846 - val_accuracy: 0.9127\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1372 - accuracy: 0.9484 - val_loss: 0.3016 - val_accuracy: 0.9100\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1316 - accuracy: 0.9511 - val_loss: 0.3002 - val_accuracy: 0.9122\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1276 - accuracy: 0.9494 - val_loss: 0.2989 - val_accuracy: 0.9122\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1264 - accuracy: 0.9513 - val_loss: 0.3068 - val_accuracy: 0.9128\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1217 - accuracy: 0.9529 - val_loss: 0.3323 - val_accuracy: 0.9113\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1151 - accuracy: 0.9557 - val_loss: 0.3152 - val_accuracy: 0.9123\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1151 - accuracy: 0.9564 - val_loss: 0.3406 - val_accuracy: 0.9090\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1096 - accuracy: 0.9581 - val_loss: 0.3474 - val_accuracy: 0.9122\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.3402 - val_accuracy: 0.9098\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1051 - accuracy: 0.9591 - val_loss: 0.3373 - val_accuracy: 0.9128\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1032 - accuracy: 0.9596 - val_loss: 0.3440 - val_accuracy: 0.9133\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0989 - accuracy: 0.9617 - val_loss: 0.3560 - val_accuracy: 0.9083\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0958 - accuracy: 0.9619 - val_loss: 0.3947 - val_accuracy: 0.9133\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0950 - accuracy: 0.9630 - val_loss: 0.3610 - val_accuracy: 0.9125\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 0.4016 - val_accuracy: 0.9108\n",
      "Epoch 43/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.3855 - val_accuracy: 0.9140\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0859 - accuracy: 0.9660 - val_loss: 0.4201 - val_accuracy: 0.9128\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0825 - accuracy: 0.9681 - val_loss: 0.4343 - val_accuracy: 0.9087\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0850 - accuracy: 0.9669 - val_loss: 0.4091 - val_accuracy: 0.9118\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0849 - accuracy: 0.9669 - val_loss: 0.4122 - val_accuracy: 0.9128\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0805 - accuracy: 0.9684 - val_loss: 0.4161 - val_accuracy: 0.9112\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0767 - accuracy: 0.9692 - val_loss: 0.4694 - val_accuracy: 0.9093\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0762 - accuracy: 0.9699 - val_loss: 0.4544 - val_accuracy: 0.9067\n",
      "Test loss: 0.4718182682991028\n",
      "Test accuracy: 0.9043999910354614\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Title: Simple Fashion MNIST convnet\n",
    "Create a convnet with the previously determined layers to cover 26x26 pixels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Setup\n",
    "\"\"\"\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_1.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x2089c613880>, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# test masking with ORB Keypoints on sample image\n",
    "# \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = (X_train[0,:,:]*255).astype(np.uint8)\n",
    "#img = cv.cvtColor(img,cv.COLOR_GRAY2RGB)\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create(edgeThreshold=3, patchSize=2, nlevels=2, fastThreshold=7, scaleFactor=7,\n",
    "                    WTA_K=4,scoreType=cv.ORB_HARRIS_SCORE, firstLevel=0, nfeatures=64)\n",
    "def get_ORB_all(orb,img):\n",
    "    img = cv.equalizeHist(img)\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp , des = orb.compute(img, kp)\n",
    "    for k in kp:\n",
    "        x = int(k.pt[0])\n",
    "        y = int(k.pt[1])\n",
    "        s = int(k.size)\n",
    "        #print(\"x\",x,\"y\",y,\"size\",s)\n",
    "    # draw only keypoints location,not size and orientation\n",
    "    img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=4)\n",
    "    img3 = cv.drawKeypoints(img*0, kp, None, color=(255,255,255), flags=4)\n",
    "    gray = cv.cvtColor(img3, cv.COLOR_BGR2GRAY)\n",
    "    # Otsu's thresholding\n",
    "    ret2,mask = cv.threshold(gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return img2,img3,mask\n",
    "    return mask\n",
    "img2,img3,mask=get_ORB_all(orb,img)\n",
    "plt.imshow(img, cmap='gray'), plt.show()\n",
    "plt.imshow(img2), plt.show()\n",
    "plt.imshow(mask, cmap='gray'), plt.show()\n",
    "masked = cv.bitwise_and(img, img, mask=mask)\n",
    "plt.imshow(masked, cmap='gray'), plt.show()\n",
    "imgadd=(1.0*img+1.0*mask)\n",
    "imgmax=np.amax(img)\n",
    "addmax=np.amax(imgadd)\n",
    "imgmask=((imgadd/addmax)*imgmax).astype(np.uint8)\n",
    "plt.imshow(imgmask, cmap='gray'), plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create keypoint  train set\n",
      "create keypoint  test set\n",
      "Train Discriminator\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 43266     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,586\n",
      "Trainable params: 43,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(120000, 28, 28, 1)\n",
      "Epoch 1/5\n",
      "657/657 [==============================] - 14s 19ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 12s 18ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 11s 17ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "(20000, 28, 28, 1)\n",
      "Test loss: 0.0022695427760481834\n",
      "Test accuracy: 0.9994500279426575\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# CNN to discriminante between Keypoints and no Keypoints areas\n",
    "# \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import cv2 as cv\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "# define Keypoint masking method\n",
    "def get_mask(img):\n",
    "    orb = cv.ORB_create(edgeThreshold=3, patchSize=2, nlevels=2, fastThreshold=7, scaleFactor=7,\n",
    "                    WTA_K=4,scoreType=cv.ORB_HARRIS_SCORE, firstLevel=0, nfeatures=64)\n",
    "    reduce=1\n",
    "    imgm = reduce*(img//reduce)\n",
    "    imgm = cv.equalizeHist(imgm)\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(imgm,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp , des = orb.compute(imgm, kp)\n",
    "    for k in kp:\n",
    "        x = int(k.pt[0])\n",
    "        y = int(k.pt[1])\n",
    "        s = int(k.size)\n",
    "        #print(\"x\",x,\"y\",y,\"size\",s)\n",
    "    # draw only keypoints location,not size and orientation\n",
    "    img3 = cv.drawKeypoints(imgm*0, kp, None, color=(255,255,255), flags=4)\n",
    "    gray = cv.cvtColor(img3, cv.COLOR_BGR2GRAY)\n",
    "    # Otsu's thresholding\n",
    "    ret2,mask = cv.threshold(gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return mask\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 2\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "# create train set\n",
    "print(\"create keypoint  train set\")\n",
    "(x,l,c)=X_train.shape\n",
    "X_train_mask=  np.zeros((2*x,l,c)).astype(\"float32\")\n",
    "Y_train_mask=  np.zeros(2*x)\n",
    "for i,img in enumerate(X_train):\n",
    "    mask=get_mask(img).astype(\"float32\")/255\n",
    "    img=img.astype(\"float32\")/255\n",
    "    X_train_mask[2*i+1]=img*mask\n",
    "    Y_train_mask[2*i+1]=0\n",
    "    negativemask=1-mask\n",
    "    X_train_mask[2*i]=img*negativemask\n",
    "    Y_train_mask[2*i]=1\n",
    "X_train_mask  = np.expand_dims(X_train_mask , -1)\n",
    "print(\"create keypoint  test set\") \n",
    "# create test set with each FashionMnist image first masked with keypoint zones \n",
    "# then another image using the negative mask\n",
    "(x,l,c)=X_test.shape\n",
    "X_test_mask=  np.zeros((2*x,l,c)).astype(\"float32\")\n",
    "Y_test_mask=  np.zeros(2*x)\n",
    "for i,img in enumerate(X_test):\n",
    "    mask=get_mask(img).astype(\"float32\")/255\n",
    "    img=img.astype(\"float32\")/255\n",
    "    X_test_mask[2*i+1]=img*mask\n",
    "    Y_test_mask[2*i+1]=0\n",
    "    negativemask=1-mask\n",
    "    X_test_mask[2*i]=img*negativemask\n",
    "    Y_test_mask[2*i]=1\n",
    "\n",
    "X_test_mask  = np.expand_dims(X_test_mask , -1)\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train_mask = keras.utils.to_categorical(Y_train_mask, num_classes)\n",
    "Y_test_mask = keras.utils.to_categorical(Y_test_mask, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "## Build the model to discriminate between keypoints and non keypoints\n",
    "\"\"\"\n",
    "print(\"Train Discriminator\")\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3),strides=(1, 1), activation=\"relu\"),\n",
    "        layers.Dropout(0.5),        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model small number of Epochs as it converges quicklu\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(X_train_mask.shape)\n",
    "model.fit(X_train_mask , Y_train_mask, batch_size=batch_size, epochs=epochs, validation_split=0.3)\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "print(X_test_mask.shape)\n",
    "score = model.evaluate(X_test_mask , Y_test_mask, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d\n",
      "conv2d (3, 3, 1, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_mask.shape (20000, 28, 28, 1)\n",
      "img.shape (1, 28, 28, 1)\n",
      "(1, 26, 26, 32)\n",
      "0.9887488 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape (1, 28, 28, 1)\n",
      "(1, 26, 26, 32)\n",
      "0.8218361 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "# recover weights, display filters and one example of features\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "pyplot.rcParams[\"figure.figsize\"] = (15,10)\n",
    "def plot_feature_maps(feature_maps,rows,cols):\n",
    "    print(np.amax(feature_maps),np.amin(feature_maps))\n",
    "    feature_maps=np.where(feature_maps>0.5,1,0)\n",
    "    ix = 1\n",
    "    for _ in range(rows):\n",
    "        for _ in range(cols):\n",
    "            # specify subplot and turn of axis\n",
    "            ax = pyplot.subplot(rows, cols, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "            ix += 1\n",
    "    pyplot.show() \n",
    "    \n",
    "# recover weights and save them to pickle file\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=layer.get_weights()\n",
    "        filters, biases=weights\n",
    "        pickle.dump( (filters, biases), open( \"weights_save.p\", \"wb\" ) )\n",
    "        pyplot.show()\n",
    "        rows=4\n",
    "        cols=8\n",
    "        # normalize filter values to 0-1 so we can visualize them\n",
    "        f, axs = pyplot.subplots(rows, cols, sharey=True)\n",
    "        n_filters, ix = filters.shape[-1], 0\n",
    "        for i in range(n_filters):\n",
    "            # get the filter\n",
    "            f = filters[:, :, :, i]\n",
    "            # specify subplot and turn of axis\n",
    "            row=ix//cols\n",
    "            col=ix-cols*row\n",
    "            ax=axs[row,col]\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            ax.imshow(f[:, :, 0], cmap='gray')\n",
    "            ix += 1\n",
    "        # show the figure\n",
    "        pyplot.show()\n",
    "        # load the image with the required shape\n",
    "        print(\"X_test_mask.shape\",X_test_mask.shape)\n",
    "        img = X_test_mask[0,:,:,:]\n",
    "        # expand dimensions so that it represents a single 'sample'\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        print(\"img.shape\",img.shape)\n",
    "        # get feature map for first hidden layer\n",
    "        # redefine model to output right after the first hidden layer\n",
    "        model_ = tf.keras.Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "        feature_maps = model_(img)\n",
    "        print(feature_maps.shape)\n",
    "        # plot all 32 maps \n",
    "        \n",
    "        plot_feature_maps(feature_maps,rows,cols)\n",
    "        \n",
    "        # second one\n",
    "        img = X_test_mask[1,:,:,:]\n",
    "        # expand dimensions so that it represents a single 'sample'\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        print(\"img.shape\",img.shape)\n",
    "        # get feature map for first hidden layer\n",
    "        # redefine model to output right after the first hidden layer\n",
    "        feature_maps = model_(img)\n",
    "        print(feature_maps.shape)\n",
    "        plot_feature_maps(feature_maps,rows,cols)\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "conv2d_4\n",
      "max_pooling2d_2\n",
      "conv2d_5\n",
      "max_pooling2d_3\n",
      "conv2d_6\n",
      "conv2d_7\n",
      "flatten_1\n",
      "dropout_1\n",
      "dense_1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.8157 - accuracy: 0.7056 - val_loss: 0.4654 - val_accuracy: 0.8210\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.5190 - accuracy: 0.8143 - val_loss: 0.4038 - val_accuracy: 0.8515\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4437 - accuracy: 0.8420 - val_loss: 0.3469 - val_accuracy: 0.8737\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3912 - accuracy: 0.8624 - val_loss: 0.3227 - val_accuracy: 0.8792\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3636 - accuracy: 0.8719 - val_loss: 0.3244 - val_accuracy: 0.8820\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3451 - accuracy: 0.8774 - val_loss: 0.2965 - val_accuracy: 0.8917\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3238 - accuracy: 0.8863 - val_loss: 0.2791 - val_accuracy: 0.8958\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3085 - accuracy: 0.8913 - val_loss: 0.2721 - val_accuracy: 0.8995\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2902 - accuracy: 0.8976 - val_loss: 0.2645 - val_accuracy: 0.9010\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2766 - accuracy: 0.9016 - val_loss: 0.2533 - val_accuracy: 0.9053\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2640 - accuracy: 0.9058 - val_loss: 0.2550 - val_accuracy: 0.9078\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2561 - accuracy: 0.9095 - val_loss: 0.2439 - val_accuracy: 0.9120\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2446 - accuracy: 0.9132 - val_loss: 0.2491 - val_accuracy: 0.9088\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2327 - accuracy: 0.9161 - val_loss: 0.2483 - val_accuracy: 0.9147\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2245 - accuracy: 0.9188 - val_loss: 0.2402 - val_accuracy: 0.9180\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2176 - accuracy: 0.9220 - val_loss: 0.2386 - val_accuracy: 0.9140\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2092 - accuracy: 0.9246 - val_loss: 0.2391 - val_accuracy: 0.9173\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2013 - accuracy: 0.9274 - val_loss: 0.2566 - val_accuracy: 0.9102\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1945 - accuracy: 0.9299 - val_loss: 0.2417 - val_accuracy: 0.9175\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1849 - accuracy: 0.9319 - val_loss: 0.2462 - val_accuracy: 0.9132\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1777 - accuracy: 0.9346 - val_loss: 0.2525 - val_accuracy: 0.9238\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1716 - accuracy: 0.9375 - val_loss: 0.2423 - val_accuracy: 0.9227\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1692 - accuracy: 0.9379 - val_loss: 0.2598 - val_accuracy: 0.9210\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1604 - accuracy: 0.9419 - val_loss: 0.2576 - val_accuracy: 0.9147\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1557 - accuracy: 0.9409 - val_loss: 0.2595 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1527 - accuracy: 0.9432 - val_loss: 0.2802 - val_accuracy: 0.9187\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1480 - accuracy: 0.9453 - val_loss: 0.2699 - val_accuracy: 0.9200\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1398 - accuracy: 0.9479 - val_loss: 0.2861 - val_accuracy: 0.9165\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1352 - accuracy: 0.9479 - val_loss: 0.2999 - val_accuracy: 0.9095\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1294 - accuracy: 0.9508 - val_loss: 0.2900 - val_accuracy: 0.9188\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1289 - accuracy: 0.9514 - val_loss: 0.2775 - val_accuracy: 0.9183\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1212 - accuracy: 0.9543 - val_loss: 0.3008 - val_accuracy: 0.9148\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1197 - accuracy: 0.9532 - val_loss: 0.2868 - val_accuracy: 0.9168\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1177 - accuracy: 0.9544 - val_loss: 0.3253 - val_accuracy: 0.9145\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1142 - accuracy: 0.9566 - val_loss: 0.3178 - val_accuracy: 0.9190\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1078 - accuracy: 0.9585 - val_loss: 0.3210 - val_accuracy: 0.9153\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1063 - accuracy: 0.9592 - val_loss: 0.3126 - val_accuracy: 0.9180\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1033 - accuracy: 0.9600 - val_loss: 0.3448 - val_accuracy: 0.9210\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1050 - accuracy: 0.9586 - val_loss: 0.3470 - val_accuracy: 0.9210\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.3613 - val_accuracy: 0.9163\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0918 - accuracy: 0.9635 - val_loss: 0.3470 - val_accuracy: 0.9142\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0898 - accuracy: 0.9650 - val_loss: 0.3697 - val_accuracy: 0.9170\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0898 - accuracy: 0.9657 - val_loss: 0.3607 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0875 - accuracy: 0.9660 - val_loss: 0.3746 - val_accuracy: 0.9100\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0860 - accuracy: 0.9664 - val_loss: 0.4014 - val_accuracy: 0.9163\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0826 - accuracy: 0.9677 - val_loss: 0.3988 - val_accuracy: 0.9170\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0776 - accuracy: 0.9691 - val_loss: 0.3804 - val_accuracy: 0.9147\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0810 - accuracy: 0.9680 - val_loss: 0.4250 - val_accuracy: 0.9165\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0817 - accuracy: 0.9674 - val_loss: 0.4302 - val_accuracy: 0.9158\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0760 - accuracy: 0.9702 - val_loss: 0.4531 - val_accuracy: 0.9195\n",
      "Test loss: 0.47225576639175415\n",
      "Test accuracy: 0.9150999784469604\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now transfer learned keypoint discriminator layer to FashionMnist categorization CNN\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Transfer the weights\n",
    "\"\"\"\n",
    "for layer in model_2.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=pickle.load( open( \"weights_save.p\", \"rb\" ) )\n",
    "        layer.set_weights(weights)\n",
    "        #layer.trainable = False  \n",
    "\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_2.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(60000,) train labels\n",
      "(10000,) test labels\n",
      "(60000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "conv2d_8\n",
      "max_pooling2d_4\n",
      "conv2d_9\n",
      "max_pooling2d_5\n",
      "conv2d_10\n",
      "conv2d_11\n",
      "flatten_2\n",
      "dropout_2\n",
      "dense_2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "422/422 [==============================] - 9s 19ms/step - loss: 0.8094 - accuracy: 0.7126 - val_loss: 0.4505 - val_accuracy: 0.8308\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4974 - accuracy: 0.8251 - val_loss: 0.3695 - val_accuracy: 0.8598\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.4243 - accuracy: 0.8501 - val_loss: 0.3405 - val_accuracy: 0.8748\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3803 - accuracy: 0.8672 - val_loss: 0.3004 - val_accuracy: 0.8878\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.3522 - accuracy: 0.8778 - val_loss: 0.2860 - val_accuracy: 0.8935\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.3276 - accuracy: 0.8855 - val_loss: 0.2743 - val_accuracy: 0.8958\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.3065 - accuracy: 0.8930 - val_loss: 0.2919 - val_accuracy: 0.8865\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2930 - accuracy: 0.8975 - val_loss: 0.2652 - val_accuracy: 0.9037\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2766 - accuracy: 0.9025 - val_loss: 0.2789 - val_accuracy: 0.8960\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2648 - accuracy: 0.9062 - val_loss: 0.2468 - val_accuracy: 0.9097\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2521 - accuracy: 0.9099 - val_loss: 0.2499 - val_accuracy: 0.9090\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2432 - accuracy: 0.9139 - val_loss: 0.2445 - val_accuracy: 0.9158\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2302 - accuracy: 0.9170 - val_loss: 0.2381 - val_accuracy: 0.9112\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2244 - accuracy: 0.9197 - val_loss: 0.2482 - val_accuracy: 0.9095\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.2146 - accuracy: 0.9227 - val_loss: 0.2562 - val_accuracy: 0.9103\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2032 - accuracy: 0.9258 - val_loss: 0.2628 - val_accuracy: 0.9087\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1979 - accuracy: 0.9271 - val_loss: 0.2533 - val_accuracy: 0.9138\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.1902 - accuracy: 0.9306 - val_loss: 0.2510 - val_accuracy: 0.9142\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1810 - accuracy: 0.9337 - val_loss: 0.2595 - val_accuracy: 0.9113\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.1756 - accuracy: 0.9354 - val_loss: 0.2577 - val_accuracy: 0.9150\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1672 - accuracy: 0.9387 - val_loss: 0.2555 - val_accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1626 - accuracy: 0.9396 - val_loss: 0.2558 - val_accuracy: 0.9190\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.1562 - accuracy: 0.9418 - val_loss: 0.2536 - val_accuracy: 0.9165\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1500 - accuracy: 0.9443 - val_loss: 0.2559 - val_accuracy: 0.9165\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1432 - accuracy: 0.9464 - val_loss: 0.2790 - val_accuracy: 0.9157\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1382 - accuracy: 0.9469 - val_loss: 0.3006 - val_accuracy: 0.9105\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1355 - accuracy: 0.9481 - val_loss: 0.2752 - val_accuracy: 0.9180\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.2806 - val_accuracy: 0.9143\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1247 - accuracy: 0.9524 - val_loss: 0.2887 - val_accuracy: 0.9168\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1202 - accuracy: 0.9541 - val_loss: 0.3077 - val_accuracy: 0.9142\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1172 - accuracy: 0.9554 - val_loss: 0.3107 - val_accuracy: 0.9162\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.1130 - accuracy: 0.9565 - val_loss: 0.3090 - val_accuracy: 0.9155\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1102 - accuracy: 0.9580 - val_loss: 0.3322 - val_accuracy: 0.9080\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1067 - accuracy: 0.9585 - val_loss: 0.3321 - val_accuracy: 0.9130\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1046 - accuracy: 0.9601 - val_loss: 0.3616 - val_accuracy: 0.9103\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1005 - accuracy: 0.9614 - val_loss: 0.3466 - val_accuracy: 0.9122\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1020 - accuracy: 0.9601 - val_loss: 0.3437 - val_accuracy: 0.9142\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0979 - accuracy: 0.9613 - val_loss: 0.3668 - val_accuracy: 0.9117\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0962 - accuracy: 0.9624 - val_loss: 0.3637 - val_accuracy: 0.9073\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0901 - accuracy: 0.9645 - val_loss: 0.3805 - val_accuracy: 0.9112\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0858 - accuracy: 0.9655 - val_loss: 0.3870 - val_accuracy: 0.9100\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0904 - accuracy: 0.9643 - val_loss: 0.4023 - val_accuracy: 0.9122\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0837 - accuracy: 0.9670 - val_loss: 0.4234 - val_accuracy: 0.9083\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0824 - accuracy: 0.9675 - val_loss: 0.4059 - val_accuracy: 0.9128\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.0800 - accuracy: 0.9686 - val_loss: 0.4351 - val_accuracy: 0.9107\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0788 - accuracy: 0.9692 - val_loss: 0.4247 - val_accuracy: 0.9120\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.4440 - val_accuracy: 0.9130\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.0756 - accuracy: 0.9701 - val_loss: 0.4533 - val_accuracy: 0.9097\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0739 - accuracy: 0.9707 - val_loss: 0.4507 - val_accuracy: 0.9100\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0717 - accuracy: 0.9721 - val_loss: 0.4473 - val_accuracy: 0.9093\n",
      "Test loss: 0.48668134212493896\n",
      "Test accuracy: 0.9110999703407288\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Freezing keypoint layer  \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import pickle\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(X_train, Y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape, \"train samples\")\n",
    "print(x_test.shape, \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(Y_train.shape, \"train labels\")\n",
    "print(y_test.shape, \"test labels\")\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model_3 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "## Transfer the weights freeze learning\n",
    "\"\"\"\n",
    "for layer in model_3.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name==\"conv2d\":\n",
    "        weights=pickle.load( open( \"weights_save.p\", \"rb\" ) )\n",
    "        layer.set_weights(weights)\n",
    "        layer.trainable = False  \n",
    "\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model_3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_3.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN - InceptionResNetV2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
